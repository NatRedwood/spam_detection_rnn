{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of RNN Architecture - Code Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as st\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.layers import GRU, SimpleRNN, Embedding, Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "full_dataset = pd.read_csv(\"C:/Users/natal/CSCI5922_NN/Lab3/spam_detection_rnn/data/SPAM text message 20170820 - Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = []\n",
    "labels = []\n",
    "\n",
    "for x, label in enumerate(full_dataset['Category']):\n",
    "    full_text.append(full_dataset['Message'][x])\n",
    "    if label == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "\n",
    "full_text = np.asarray(full_text)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of separate messages:  5572\n",
      "Size of labels:  5572\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of separate messages: \", len(full_text))\n",
    "print(\"Size of labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split - for basic full test split (all sequence lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Train size:  3900 \n",
      "Test size:  1672\n",
      "Tokens size:  9004\n",
      "Data size after tokenizing:  (5572, 500)\n",
      "Train x shape after split:  (3900, 500) \n",
      "Train y shape after split:  (3900,)\n",
      "Test x shape after split:  (1672, 500) \n",
      "Test y shape after split:  (1672,)\n"
     ]
    }
   ],
   "source": [
    "# features - number of words\n",
    "max_features = 10000\n",
    "\n",
    "# Splitting the data\n",
    "train = int(5572 * .7)\n",
    "#print(train)\n",
    "test = int(5572 - train)\n",
    "#print(test)\n",
    "\n",
    "# Checking the shapes are correct\n",
    "print(len(full_text) == (train + test))\n",
    "print(\"Train size: \", train, \"\\nTest size: \", test)\n",
    "\n",
    "# Tokenizning \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(full_text)\n",
    "sequences = tokenizer.texts_to_sequences(full_text)\n",
    "\n",
    "# after, stop putting more words\n",
    "max_len = 500\n",
    "\n",
    "idx_word = tokenizer.word_index\n",
    "print(\"Tokens size: \", len(idx_word))\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Checking the shape\n",
    "print(\"Data size after tokenizing: \", padded_sequences.shape)\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.arange(padded_sequences.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "padded_sequences_idx = padded_sequences[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = padded_sequences_idx[:train]\n",
    "y_train = labels[:train]\n",
    "x_test = padded_sequences_idx[train:]\n",
    "y_test = labels[train:]\n",
    "\n",
    "# Checking the shapes after splitting\n",
    "print(\"Train x shape after split: \", x_train.shape, \"\\nTrain y shape after split: \", y_train.shape)\n",
    "print(\"Test x shape after split: \", x_test.shape, \"\\nTest y shape after split: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the messages' length - necessary for further splitting the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Sentence example from the messages:\n",
      "\n",
      " FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Checking the number of messages: 5572\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Sentence example after tokenizing: \n",
      "\n",
      " ['FreeMsg', 'Hey', 'there', 'darling', \"it's\", 'been', '3', \"week's\", 'now', 'and', 'no', 'word', 'back!', \"I'd\", 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still?', 'Tb', 'ok!', 'XxX', 'std', 'chgs', 'to', 'send,', '£1.50', 'to', 'rcv']\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Length of the first 20 messages: \n",
      "\n",
      "[20, 6, 28, 11, 13, 32, 16, 26, 26, 29, 21, 26, 26, 37, 8, 19, 4, 19, 13, 24]\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Sorted list; descending:\n",
      "\n",
      "[171, 162, 125, 125, 121, 119, 99, 96, 96, 95, 89, 88, 80, 79, 79, 79, 77, 77, 76, 73]\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "The mean of the first set in the desceding list (large): 28.324178782983306\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "The mean of the first set in the desceding list (medium): 12.775982767905223\n",
      "Lengths of 20 messages before the frist division: [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "The mean of the first set in the desceding list (short): 5.889128094725511\n",
      "Lengths of 20 messages before the second division: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Chosen boundaries for lengths:\n",
      "\n",
      "Short: 9\n",
      "Medium: 18\n",
      "Long: 170\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of messages to perform the division of the test set based on the number of words\n",
    "# Creating the boundaries for: Short, medium and long inputs\n",
    "\n",
    "texts_list = full_text.tolist()\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"Sentence example from the messages:\\n\\n {texts_list[5]}\")\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "def tokenizing():\n",
    "    splitted = []\n",
    "    for x in texts_list:\n",
    "        splitted.append(x.split(' '))\n",
    "    return splitted\n",
    "\n",
    "splitted_messages = tokenizing()\n",
    "print(f\"Checking the number of messages: {len(splitted_messages)}\")\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"Sentence example after tokenizing: \\n\\n {splitted_messages[5]}\")\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "def counting_length():\n",
    "    lengths = []\n",
    "    for x in splitted_messages:\n",
    "        lengths.append(len(x))\n",
    "    return lengths\n",
    "\n",
    "print(f\"Length of the first 20 messages: \\n\\n{counting_length()[:20]}\")\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "sorted_counts = sorted(counting_length(), reverse=True)\n",
    "print(f\"Sorted list; descending:\\n\\n{sorted_counts[:20]}\")\n",
    "\n",
    "div = math.floor(len(texts_list)/3)\n",
    "long_lenghts = sorted_counts[:div]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"The mean of the first set in the desceding list (large): {st.mean(long_lenghts)}\")\n",
    "\n",
    "medium_lenghts = sorted_counts[div:int(2*div)]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"The mean of the first set in the desceding list (medium): {st.mean(medium_lenghts)}\")\n",
    "print(f\"Lengths of 20 messages before the frist division: {sorted_counts[div-20:int(2*div)][:20]}\")\n",
    "\n",
    "short_lenghts = sorted_counts[2*div:]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"The mean of the first set in the desceding list (short): {st.mean(short_lenghts)}\")\n",
    "print(f\"Lengths of 20 messages before the second division: {sorted_counts[(2*div-20):][:20]}\")\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "\n",
    "short=9\n",
    "medium=18\n",
    "long=170\n",
    "print(f\"Chosen boundaries for lengths:\\n\\nShort: {short}\\nMedium: {medium}\\nLong: {long}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data preparation for test-size experiments based on the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Length of short messages dataset: 1861\n",
      "\n",
      "Example of a message: 0    I didnt get anything da\n",
      "Name: messages, dtype: object\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Length of medium messages dataset: 1843\n",
      "\n",
      "Example of a message: 0    I call you later, don't have network. If urgnt, sms me.\n",
      "Name: messages, dtype: object\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Length of long messages dataset: 1868\n",
      "\n",
      "Example of a long message: 0    I don't want you to leave. But i'm barely doing what i can to stay sane. fighting with you constantly isn't helping.\n",
      "Name: messages, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe with messages and word counts\n",
    "\n",
    "#Checking the lengths of texts and labels\n",
    "len(texts_list)\n",
    "len(labels)\n",
    "\n",
    "#Making sure the numpy arrays are converted to lists\n",
    "type(texts_list)\n",
    "type(labels)\n",
    "\n",
    "labels_list = labels.tolist()\n",
    "\n",
    "type(labels_list)\n",
    "\n",
    "#Creating a dictionary and then making a dataframe \n",
    "dict_full_dataset = {'messages': texts_list, 'labels': labels_list}\n",
    "df_full_dataset = pd.DataFrame(dict_full_dataset)\n",
    "df_full_dataset.head()\n",
    "\n",
    "#Creating an additional column with word counts\n",
    "df_full_dataset['word_count'] = df_full_dataset['messages'].str.split().str.len()\n",
    "df_full_dataset\n",
    "\n",
    "#Setting df options to display example messages\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Creating three new dataframes based on the conditions of the length of seqeunces\n",
    "#Boundaries for nummber of words were created in the previous cells with the analysis of the dataset\n",
    "df_short_messages = df_full_dataset[df_full_dataset['word_count']<short]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"Length of short messages dataset: {len(df_short_messages)}\\n\")\n",
    "print(f\"Example of a message: {df_short_messages['messages'].sample(1,ignore_index=True)}\")\n",
    "\n",
    "df_medium_messages = df_full_dataset[(df_full_dataset['word_count']<=medium) & (df_full_dataset['word_count']>=short)]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"Length of medium messages dataset: {len(df_medium_messages)}\\n\")\n",
    "print(f\"Example of a message: {df_medium_messages['messages'].sample(1,ignore_index=True)}\")\n",
    "\n",
    "df_long_messages = df_full_dataset[df_full_dataset['word_count']>medium]\n",
    "print(\"\\n------------------------------------------------------\\n\")\n",
    "print(f\"Length of long messages dataset: {len(df_long_messages)}\\n\")\n",
    "print(f\"Example of a long message: {df_long_messages['messages'].sample(1,ignore_index=True)}\")\n",
    "\n",
    "#Reset df options\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset accroding to sequence size for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the length of messages == length of labels: True\n",
      "Checking the length of messages == length of labels: True\n",
      "Checking the length of messages == length of labels: True\n"
     ]
    }
   ],
   "source": [
    "#Extracting lists from df of short messages and checking length are compatible\n",
    "short_list=df_short_messages['messages'].to_list()\n",
    "short_list_labels=df_short_messages['labels'].to_list()\n",
    "print(f\"Checking the length of messages == length of labels: {len(short_list)==len(short_list_labels)}\")\n",
    "\n",
    "#Extracting lists from df of medium messages and checking length are compatible\n",
    "m_list=df_medium_messages['messages'].to_list()\n",
    "m_list_labels=df_medium_messages['labels'].to_list()\n",
    "print(f\"Checking the length of messages == length of labels: {len(m_list)==len(m_list_labels)}\")\n",
    "\n",
    "#Extracting lists from df of long messages and checking length are compatible\n",
    "l_list=df_long_messages['messages'].to_list()\n",
    "l_list_labels=df_long_messages['labels'].to_list()\n",
    "print(f\"Checking the length of messages == length of labels: {len(l_list)==len(l_list_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Creating numpy arrays\n",
    "full_text_short = np.asarray(short_list)\n",
    "labels_short = np.asarray(short_list_labels)\n",
    "\n",
    "full_text_medium = np.asarray(m_list)\n",
    "labels_medium = np.asarray(m_list_labels)\n",
    "\n",
    "full_text_long = np.asarray(l_list)\n",
    "labels_long = np.asarray(l_list_labels)\n",
    "print(type(labels_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the full test data has ~1600 entries, I will not further split the created sets into train/test\n",
    "#The current sets are ~1800 so it's comparable to the original full test set\n",
    "\n",
    "#Steps as above to vectorize the sequences of words\n",
    "\n",
    "def vectorize_data(x,y):\n",
    "    # Tokenizning\n",
    "    tokenizer = Tokenizer()\n",
    "    fitted = tokenizer.fit_on_texts(x)\n",
    "    sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "    # after, stop putting more words\n",
    "    max_len = 500\n",
    "\n",
    "    idx_word = tokenizer.word_index\n",
    "    print(\"Tokens size: \", len(idx_word))\n",
    "\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "    # Checking the shape\n",
    "    print(\"Data size after tokenizing: \", padded.shape)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    indices = np.arange(padded.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    padded_sequences_idx = padded[indices]\n",
    "    labels = y[indices]\n",
    "\n",
    "    x_data = padded_sequences_idx[:]\n",
    "    y_data = labels[:]\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens size:  2357\n",
      "Data size after tokenizing:  (1861, 500)\n",
      "Tokens size:  3846\n",
      "Data size after tokenizing:  (1843, 500)\n",
      "Tokens size:  6659\n",
      "Data size after tokenizing:  (1868, 500)\n"
     ]
    }
   ],
   "source": [
    "x_test_short, y_test_short = vectorize_data(full_text_short, labels_short)\n",
    "x_test_medium, y_test_medium = vectorize_data(full_text_medium, labels_medium)\n",
    "x_test_long, y_test_long = vectorize_data(full_text_long, labels_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "122/122 [==============================] - 14s 101ms/step - loss: 0.2278 - acc: 0.9208\n",
      "Epoch 2/15\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 0.0577 - acc: 0.9831\n",
      "Epoch 3/15\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 0.0397 - acc: 0.9892\n",
      "Epoch 4/15\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 0.0271 - acc: 0.9923\n",
      "Epoch 5/15\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 0.0136 - acc: 0.9956\n",
      "Epoch 6/15\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 7/15\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 0.0065 - acc: 0.9987\n",
      "Epoch 8/15\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 9/15\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 10/15\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 11/15\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 8.1505e-04 - acc: 0.9995\n",
      "Epoch 12/15\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 3.0906e-04 - acc: 1.0000\n",
      "Epoch 13/15\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 3.7666e-04 - acc: 1.0000\n",
      "Epoch 14/15\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.5793e-04 - acc: 1.0000\n",
      "Epoch 15/15\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 1.7114e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Vanilla test RNN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 64))\n",
    "model.add(SimpleRNN(64,input_shape=x_train.shape,return_sequences=False, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer ='rmsprop',metrics=['acc'])\n",
    "\n",
    "model_rnn = model.fit(x_train, y_train, epochs = 15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of first model_rnn\n",
    "\n",
    "After running the very first model, it was observed that the model is probably overfitting the data. The accuracy after the epoch 15 is 100% and the model probably learns the noise. The model is not learning objectively and is fit too much to the training data. Before I actually start runnig the 3 models (vanilla RNN, LSTM and GRU), I will treat the model overfitting:\n",
    "* reducing the network's capacity --> decreasing the number of units in the model's layers\n",
    "* applying regularization technique --> penalizing very large weights\n",
    "* changing optimizer to Adam\n",
    "* increasing the batch size --> the model will learn lesser noise; it will help take a more reasonable 'step' for minima\n",
    "* adding dropout layers --> by dropping some layer of the network, I will let the model generalize better on unseen examples; it won't be trained for details and noises of the training data\n",
    "\n",
    "I will call this model a test model, apply the mentioned changes and start building the 3 RNN models for the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### Fine-grained analysis with respect to input length\n",
    "\n",
    "Each model (vanilla RNN, LSTM and GRU) is ran on the full test set (all sequence lengths) and on experimental test sets by dividing the test set into short, medium and long inputs roughly equl-sized based on the number of words observed in the test set examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of test sets:\n",
      "1672\n",
      "1861\n",
      "1843\n",
      "1868\n"
     ]
    }
   ],
   "source": [
    "# Checking numbers of test sets\n",
    "\n",
    "print(\"Lengths of test sets:\")\n",
    "test_sets=[y_test,y_test_short,y_test_medium,y_test_long]\n",
    "for x in test_sets:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "After running the three models on short and medium sets, I observed a very small precision and recall. After that, I ran the model again with the option to show tp, fp, tn and fn. After the division of the sets for input length difference, the data was significantly imbalanced. There are too little positive examples. The model below is another test model saved with the precision and recall computed for imbalanced data. The actual three models will have class weights passed in the model. The weights will force the algorithm to treat every entry of class 1 (positive/spam) as x entries of class 0. Then, the loss will become a weighted average. There were several experiemnts conducted on the class weigths. The ratio of 1:50 (pos:neg) was too high and caused the scarcity of the negative examples. The final weight was calucated automatically using the class_weight module in Keras library. After several manual experiments to set up the ratio to 1:25, 1:50 and 1:75, the 'balanced' weight computation included in Keras resulted in much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Positive: 522\n",
      "Negative: 3378\n",
      "TEST\n",
      "Positive: 225\n",
      "Negative: 1447\n",
      "SHORT\n",
      "Positive: 251\n",
      "Negative: 1610\n",
      "MEDIUM\n",
      "Positive: 267\n",
      "Negative: 1576\n",
      "LONG\n",
      "Positive: 229\n",
      "Negative: 1639\n"
     ]
    }
   ],
   "source": [
    "count_non0 = np.count_nonzero(y_train)\n",
    "count_0 = len(y_train) - count_non0\n",
    "print(f\"TRAIN\\nPositive: {count_non0}\\nNegative: {count_0}\")\n",
    "\n",
    "count_non0 = np.count_nonzero(y_test)\n",
    "count_0 = len(y_test) - count_non0\n",
    "print(f\"TEST\\nPositive: {count_non0}\\nNegative: {count_0}\")\n",
    "\n",
    "count_non0 = np.count_nonzero(y_test_short)\n",
    "count_0 = len(y_test_short) - count_non0\n",
    "print(f\"SHORT\\nPositive: {count_non0}\\nNegative: {count_0}\")\n",
    "\n",
    "count_non0 = np.count_nonzero(y_test_medium)\n",
    "count_0 = len(y_test_medium) - count_non0\n",
    "print(f\"MEDIUM\\nPositive: {count_non0}\\nNegative: {count_0}\")\n",
    "\n",
    "count_non0 = np.count_nonzero(y_test_long)\n",
    "count_0 = len(y_test_long) - count_non0\n",
    "print(f\"LONG\\nPositive: {count_non0}\\nNegative: {count_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vanilla RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: https://stackoverflow.com/questions/61835742/same-value-for-keras-2-3-0-metrics-accuracy-precision-and-recall\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "      y_pred = y_pred[:,1:2]\n",
    "      y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 5s 115ms/step - loss: 0.6972 - acc: 0.8608 - tp: 5.0000 - fp: 26.0000 - tn: 3352.0000 - fn: 517.0000 - accuracy: 0.8608 - precision: 0.0194 - recall: 0.0122 - auc: 0.5450\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.5819 - acc: 0.8662 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 522.0000 - accuracy: 0.8662 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6500\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.5345 - acc: 0.8662 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 522.0000 - accuracy: 0.8662 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8927\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 0.5039 - acc: 0.8662 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 522.0000 - accuracy: 0.8662 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9866\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 0.4158 - acc: 0.9277 - tp: 242.0000 - fp: 2.0000 - tn: 3376.0000 - fn: 280.0000 - accuracy: 0.9277 - precision: 0.7452 - recall: 0.4945 - auc: 0.9787\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 0.3043 - acc: 0.9731 - tp: 418.0000 - fp: 1.0000 - tn: 3377.0000 - fn: 104.0000 - accuracy: 0.9731 - precision: 0.9948 - recall: 0.8087 - auc: 0.9969\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 0.2463 - acc: 0.9862 - tp: 470.0000 - fp: 2.0000 - tn: 3376.0000 - fn: 52.0000 - accuracy: 0.9862 - precision: 0.9957 - recall: 0.8960 - auc: 0.9984\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.2160 - acc: 0.9895 - tp: 482.0000 - fp: 1.0000 - tn: 3377.0000 - fn: 40.0000 - accuracy: 0.9895 - precision: 0.9980 - recall: 0.9282 - auc: 0.9994\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 0.1953 - acc: 0.9931 - tp: 495.0000 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 27.0000 - accuracy: 0.9931 - precision: 1.0000 - recall: 0.9507 - auc: 0.9997\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.1802 - acc: 0.9949 - tp: 502.0000 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 20.0000 - accuracy: 0.9949 - precision: 1.0000 - recall: 0.9648 - auc: 0.9997\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.1683 - acc: 0.9969 - tp: 510.0000 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 12.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9762 - auc: 0.9998\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.1580 - acc: 0.9974 - tp: 512.0000 - fp: 0.0000e+00 - tn: 3378.0000 - fn: 10.0000 - accuracy: 0.9974 - precision: 1.0000 - recall: 0.9814 - auc: 0.9999\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the full test set:\n",
      "53/53 [==============================] - 3s 18ms/step - loss: 0.1916 - acc: 0.9839 - tp: 201.0000 - fp: 3.0000 - tn: 1444.0000 - fn: 24.0000 - accuracy: 0.9839 - precision: 0.9847 - recall: 0.8992 - auc: 0.9943\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the SHORT test set:\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.6012 - acc: 0.8641 - tp: 0.0000e+00 - fp: 2.0000 - tn: 1608.0000 - fn: 251.0000 - accuracy: 0.8641 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5143\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the MEDIUM test set:\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.6432 - acc: 0.8502 - tp: 0.0000e+00 - fp: 9.0000 - tn: 1567.0000 - fn: 267.0000 - accuracy: 0.8502 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4666\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the LONG test set:\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 0.5960 - acc: 0.8501 - tp: 9.0000 - fp: 60.0000 - tn: 1579.0000 - fn: 220.0000 - accuracy: 0.8501 - precision: 0.0960 - recall: 0.0340 - auc: 0.5584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5959974527359009,\n",
       " 'acc': 0.8501070737838745,\n",
       " 'tp': 9.0,\n",
       " 'fp': 60.0,\n",
       " 'tn': 1579.0,\n",
       " 'fn': 220.0,\n",
       " 'accuracy': 0.8501070737838745,\n",
       " 'precision': 0.09604518860578537,\n",
       " 'recall': 0.03403954952955246,\n",
       " 'auc': 0.5583977699279785}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test vanilla RNN model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 15))\n",
    "model.add(SimpleRNN(15,input_shape=x_train.shape, activation='tanh',recurrent_regularizer='l2'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics=['acc', keras.metrics.TruePositives(name='tp'), keras.metrics.FalsePositives(name='fp'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.FalseNegatives(name='fn'), keras.metrics.BinaryAccuracy(name='accuracy'),precision,recall,keras.metrics.AUC(name='auc')])\n",
    "\n",
    "model_vanilla_rnn = model.fit(x_train, y_train, epochs = 12, batch_size=256)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the full test set:\")\n",
    "model.evaluate(x_test,y_test, verbose=1, return_dict=True)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the SHORT test set:\")\n",
    "model.evaluate(x_test_short,y_test_short, verbose=1, return_dict=True)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the MEDIUM test set:\")\n",
    "model.evaluate(x_test_medium,y_test_medium, verbose=1, return_dict=True)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the LONG test set:\")\n",
    "model.evaluate(x_test_long,y_test_long, verbose=1, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natal\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "num_units=15\n",
    "activation_rnn='tanh'\n",
    "regularizer = 'l2'\n",
    "activation_output = 'sigmoid'\n",
    "loss = 'binary_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.TrueNegatives(name='tn'),\n",
    "           keras.metrics.FalseNegatives(name='fn'),\n",
    "           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "           precision,\n",
    "           recall,\n",
    "           keras.metrics.AUC(name='auc')]\n",
    "epochs = 12\n",
    "batch_size= 256\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 5s 123ms/step - loss: 0.8203 - tp: 361.0000 - fp: 1603.0000 - tn: 1775.0000 - fn: 161.0000 - accuracy: 0.5477 - precision: 0.2622 - recall: 0.6943 - auc: 0.6483\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.7161 - tp: 454.0000 - fp: 278.0000 - tn: 3100.0000 - fn: 68.0000 - accuracy: 0.9113 - precision: 0.6229 - recall: 0.8740 - auc: 0.9624\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 0.5675 - tp: 483.0000 - fp: 162.0000 - tn: 3216.0000 - fn: 39.0000 - accuracy: 0.9485 - precision: 0.7642 - recall: 0.9275 - auc: 0.9833\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 0.4194 - tp: 491.0000 - fp: 42.0000 - tn: 3336.0000 - fn: 31.0000 - accuracy: 0.9813 - precision: 0.9257 - recall: 0.9324 - auc: 0.9926\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.3370 - tp: 493.0000 - fp: 13.0000 - tn: 3365.0000 - fn: 29.0000 - accuracy: 0.9892 - precision: 0.9683 - recall: 0.9384 - auc: 0.9959\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.2916 - tp: 503.0000 - fp: 5.0000 - tn: 3373.0000 - fn: 19.0000 - accuracy: 0.9938 - precision: 0.9902 - recall: 0.9650 - auc: 0.9974\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 0.3211 - tp: 511.0000 - fp: 212.0000 - tn: 3166.0000 - fn: 11.0000 - accuracy: 0.9428 - precision: 0.9396 - recall: 0.9798 - auc: 0.9949\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 0.3004 - tp: 516.0000 - fp: 222.0000 - tn: 3156.0000 - fn: 6.0000 - accuracy: 0.9415 - precision: 0.9429 - recall: 0.9886 - auc: 0.9967\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 0.2311 - tp: 516.0000 - fp: 1.0000 - tn: 3377.0000 - fn: 6.0000 - accuracy: 0.9982 - precision: 0.9982 - recall: 0.9889 - auc: 0.9996\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.2535 - tp: 517.0000 - fp: 165.0000 - tn: 3213.0000 - fn: 5.0000 - accuracy: 0.9564 - precision: 0.9489 - recall: 0.9768 - auc: 0.9987\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.2142 - tp: 517.0000 - fp: 1.0000 - tn: 3377.0000 - fn: 5.0000 - accuracy: 0.9985 - precision: 0.9983 - recall: 0.9915 - auc: 0.9998\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.2111 - tp: 519.0000 - fp: 52.0000 - tn: 3326.0000 - fn: 3.0000 - accuracy: 0.9859 - precision: 0.9604 - recall: 0.9942 - auc: 0.9997\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the full test set:\n",
      "53/53 [==============================] - 2s 20ms/step - loss: 0.2527 - tp: 201.0000 - fp: 18.0000 - tn: 1429.0000 - fn: 24.0000 - accuracy: 0.9749 - precision: 0.9161 - recall: 0.9001 - auc: 0.9871\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the SHORT test set:\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 0.5673 - tp: 1.0000 - fp: 4.0000 - tn: 1606.0000 - fn: 250.0000 - accuracy: 0.8635 - precision: 0.0169 - recall: 0.0034 - auc: 0.5258   \n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the MEDIUM test set:\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 0.6220 - tp: 7.0000 - fp: 51.0000 - tn: 1525.0000 - fn: 260.0000 - accuracy: 0.8313 - precision: 0.0761 - recall: 0.0234 - auc: 0.4683\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the LONG test set:\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 0.5949 - tp: 18.0000 - fp: 107.0000 - tn: 1532.0000 - fn: 211.0000 - accuracy: 0.8298 - precision: 0.1271 - recall: 0.0691 - auc: 0.5442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.594924807548523,\n",
       " 18.0,\n",
       " 107.0,\n",
       " 1532.0,\n",
       " 211.0,\n",
       " 0.8297644257545471,\n",
       " 0.12711864709854126,\n",
       " 0.06905496120452881,\n",
       " 0.5441983342170715]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vanilla RNN model 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, num_units))\n",
    "model.add(SimpleRNN(num_units,input_shape=x_train.shape, activation=activation_rnn,recurrent_regularizer=regularizer))\n",
    "model.add(Dense(1, activation=activation_output))\n",
    "model.compile(loss = loss, optimizer=optimizer,metrics=metrics)\n",
    "\n",
    "model_vanilla_rnn1 = model.fit(x_train, y_train, epochs = epochs, batch_size=batch_size,class_weight=class_weights)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the full test set:\")\n",
    "model.evaluate(x_test,y_test, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the SHORT test set:\")\n",
    "model.evaluate(x_test_short,y_test_short, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the MEDIUM test set:\")\n",
    "model.evaluate(x_test_medium,y_test_medium, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the LONG test set:\")\n",
    "model.evaluate(x_test_long,y_test_long, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 11s 330ms/step - loss: 0.8283 - tp: 427.0000 - fp: 1597.0000 - tn: 3420.0000 - fn: 324.0000 - accuracy: 0.6670 - precision: 0.2287 - recall: 0.8097 - auc: 0.6066\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 6s 360ms/step - loss: 0.7930 - tp: 451.0000 - fp: 149.0000 - tn: 3229.0000 - fn: 71.0000 - accuracy: 0.9436 - precision: 0.7952 - recall: 0.8705 - auc: 0.9590\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 0.7508 - tp: 465.0000 - fp: 30.0000 - tn: 3348.0000 - fn: 57.0000 - accuracy: 0.9777 - precision: 0.9409 - recall: 0.8865 - auc: 0.9876\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.6831 - tp: 465.0000 - fp: 12.0000 - tn: 3366.0000 - fn: 57.0000 - accuracy: 0.9823 - precision: 0.9760 - recall: 0.8822 - auc: 0.9905\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.5492 - tp: 449.0000 - fp: 5.0000 - tn: 3373.0000 - fn: 73.0000 - accuracy: 0.9800 - precision: 0.9882 - recall: 0.8559 - auc: 0.9847\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.3908 - tp: 465.0000 - fp: 4.0000 - tn: 3374.0000 - fn: 57.0000 - accuracy: 0.9844 - precision: 0.9882 - recall: 0.8857 - auc: 0.9953\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 5s 319ms/step - loss: 0.2847 - tp: 488.0000 - fp: 11.0000 - tn: 3367.0000 - fn: 34.0000 - accuracy: 0.9885 - precision: 0.9784 - recall: 0.9330 - auc: 0.9959\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 5s 319ms/step - loss: 0.2207 - tp: 498.0000 - fp: 17.0000 - tn: 3361.0000 - fn: 24.0000 - accuracy: 0.9895 - precision: 0.9492 - recall: 0.9571 - auc: 0.9972\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.1817 - tp: 501.0000 - fp: 11.0000 - tn: 3367.0000 - fn: 21.0000 - accuracy: 0.9918 - precision: 0.9797 - recall: 0.9534 - auc: 0.9983\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.1536 - tp: 515.0000 - fp: 12.0000 - tn: 3366.0000 - fn: 7.0000 - accuracy: 0.9951 - precision: 0.9761 - recall: 0.9864 - auc: 0.9991\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 7s 408ms/step - loss: 0.1326 - tp: 516.0000 - fp: 7.0000 - tn: 3371.0000 - fn: 6.0000 - accuracy: 0.9967 - precision: 0.9867 - recall: 0.9896 - auc: 0.9994\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 6s 381ms/step - loss: 0.1165 - tp: 516.0000 - fp: 5.0000 - tn: 3373.0000 - fn: 6.0000 - accuracy: 0.9972 - precision: 0.9897 - recall: 0.9888 - auc: 0.9997\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the full test set:\n",
      "53/53 [==============================] - 4s 44ms/step - loss: 0.1327 - tp: 213.0000 - fp: 11.0000 - tn: 1436.0000 - fn: 12.0000 - accuracy: 0.9862 - precision: 0.9517 - recall: 0.9510 - auc: 0.9947\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the SHORT test set:\n",
      "59/59 [==============================] - 2s 40ms/step - loss: 0.4715 - tp: 3.0000 - fp: 12.0000 - tn: 1598.0000 - fn: 248.0000 - accuracy: 0.8603 - precision: 0.0424 - recall: 0.0115 - auc: 0.5162\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the MEDIUM test set:\n",
      "58/58 [==============================] - 2s 36ms/step - loss: 0.5321 - tp: 7.0000 - fp: 48.0000 - tn: 1528.0000 - fn: 260.0000 - accuracy: 0.8329 - precision: 0.0833 - recall: 0.0284 - auc: 0.4766\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the LONG test set:\n",
      "59/59 [==============================] - 3s 42ms/step - loss: 0.5289 - tp: 28.0000 - fp: 156.0000 - tn: 1483.0000 - fn: 201.0000 - accuracy: 0.8089 - precision: 0.1345 - recall: 0.1191 - auc: 0.5520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5288983583450317,\n",
       " 28.0,\n",
       " 156.0,\n",
       " 1483.0,\n",
       " 201.0,\n",
       " 0.8088865280151367,\n",
       " 0.13446328043937683,\n",
       " 0.11905495077371597,\n",
       " 0.5520247220993042]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, num_units))\n",
    "model.add(LSTM(num_units,input_shape=x_train.shape, activation=activation_rnn,recurrent_regularizer=regularizer))\n",
    "model.add(Dense(1, activation=activation_output))\n",
    "model.compile(loss = loss, optimizer=optimizer,metrics=metrics)\n",
    "\n",
    "model_lstm = model.fit(x_train, y_train, epochs = epochs, batch_size=batch_size,class_weight=class_weights)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the full test set:\")\n",
    "model.evaluate(x_test,y_test, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the SHORT test set:\")\n",
    "model.evaluate(x_test_short,y_test_short, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the MEDIUM test set:\")\n",
    "model.evaluate(x_test_medium,y_test_medium, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the LONG test set:\")\n",
    "model.evaluate(x_test_long,y_test_long, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16/16 [==============================] - 10s 290ms/step - loss: 0.8269 - tp: 464.0000 - fp: 1802.0000 - tn: 3215.0000 - fn: 287.0000 - accuracy: 0.6378 - precision: 0.2330 - recall: 0.7835 - auc: 0.6366\n",
      "Epoch 2/12\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.7857 - tp: 477.0000 - fp: 453.0000 - tn: 2925.0000 - fn: 45.0000 - accuracy: 0.8723 - precision: 0.5160 - recall: 0.9185 - auc: 0.9570\n",
      "Epoch 3/12\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.7336 - tp: 476.0000 - fp: 103.0000 - tn: 3275.0000 - fn: 46.0000 - accuracy: 0.9618 - precision: 0.8210 - recall: 0.9134 - auc: 0.9854\n",
      "Epoch 4/12\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.6595 - tp: 486.0000 - fp: 81.0000 - tn: 3297.0000 - fn: 36.0000 - accuracy: 0.9700 - precision: 0.8622 - recall: 0.9326 - auc: 0.9923\n",
      "Epoch 5/12\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.5472 - tp: 485.0000 - fp: 47.0000 - tn: 3331.0000 - fn: 37.0000 - accuracy: 0.9785 - precision: 0.9140 - recall: 0.9188 - auc: 0.9941\n",
      "Epoch 6/12\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.3879 - tp: 495.0000 - fp: 24.0000 - tn: 3354.0000 - fn: 27.0000 - accuracy: 0.9869 - precision: 0.9504 - recall: 0.9519 - auc: 0.9966\n",
      "Epoch 7/12\n",
      "16/16 [==============================] - 5s 289ms/step - loss: 0.2357 - tp: 499.0000 - fp: 11.0000 - tn: 3367.0000 - fn: 23.0000 - accuracy: 0.9913 - precision: 0.9797 - recall: 0.9528 - auc: 0.9947\n",
      "Epoch 8/12\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 0.1609 - tp: 509.0000 - fp: 14.0000 - tn: 3364.0000 - fn: 13.0000 - accuracy: 0.9931 - precision: 0.9744 - recall: 0.9773 - auc: 0.9969\n",
      "Epoch 9/12\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.1302 - tp: 512.0000 - fp: 13.0000 - tn: 3365.0000 - fn: 10.0000 - accuracy: 0.9941 - precision: 0.9764 - recall: 0.9817 - auc: 0.9982\n",
      "Epoch 10/12\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.1134 - tp: 515.0000 - fp: 11.0000 - tn: 3367.0000 - fn: 7.0000 - accuracy: 0.9954 - precision: 0.9796 - recall: 0.9868 - auc: 0.9987\n",
      "Epoch 11/12\n",
      "16/16 [==============================] - 5s 291ms/step - loss: 0.1011 - tp: 517.0000 - fp: 7.0000 - tn: 3371.0000 - fn: 5.0000 - accuracy: 0.9969 - precision: 0.9789 - recall: 0.9905 - auc: 0.9992\n",
      "Epoch 12/12\n",
      "16/16 [==============================] - 5s 289ms/step - loss: 0.0916 - tp: 517.0000 - fp: 5.0000 - tn: 3373.0000 - fn: 5.0000 - accuracy: 0.9974 - precision: 0.9909 - recall: 0.9910 - auc: 0.9995\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the full test set:\n",
      "53/53 [==============================] - 3s 29ms/step - loss: 0.1161 - tp: 212.0000 - fp: 9.0000 - tn: 1438.0000 - fn: 13.0000 - accuracy: 0.9868 - precision: 0.9616 - recall: 0.9447 - auc: 0.9946\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the SHORT test set:\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.5967 - tp: 5.0000 - fp: 24.0000 - tn: 1586.0000 - fn: 246.0000 - accuracy: 0.8549 - precision: 0.0763 - recall: 0.0164 - auc: 0.5251\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the MEDIUM test set:\n",
      "58/58 [==============================] - 2s 29ms/step - loss: 0.6555 - tp: 8.0000 - fp: 76.0000 - tn: 1500.0000 - fn: 259.0000 - accuracy: 0.8182 - precision: 0.0675 - recall: 0.0286 - auc: 0.4710\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "Model evaluation on the LONG test set:\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.6000 - tp: 34.0000 - fp: 169.0000 - tn: 1470.0000 - fn: 195.0000 - accuracy: 0.8051 - precision: 0.1430 - recall: 0.1388 - auc: 0.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6000329256057739,\n",
       " 34.0,\n",
       " 169.0,\n",
       " 1470.0,\n",
       " 195.0,\n",
       " 0.8051391839981079,\n",
       " 0.1429782211780548,\n",
       " 0.1388491541147232,\n",
       " 0.5571322441101074]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, num_units))\n",
    "model.add(GRU(num_units,input_shape=x_train.shape, activation=activation_rnn,recurrent_regularizer=regularizer))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = loss, optimizer=optimizer,metrics=metrics)\n",
    "\n",
    "model_gru = model.fit(x_train, y_train, epochs = epochs, batch_size=batch_size,class_weight=class_weights)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the full test set:\")\n",
    "model.evaluate(x_test,y_test, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the SHORT test set:\")\n",
    "model.evaluate(x_test_short,y_test_short, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the MEDIUM test set:\")\n",
    "model.evaluate(x_test_medium,y_test_medium, verbose=1)\n",
    "print(\"\\n---------------------------------------------------\\n\")\n",
    "print(\"Model evaluation on the LONG test set:\")\n",
    "model.evaluate(x_test_long,y_test_long, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of Pretrained Word Embedding - Code Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b31755cbf75356c393a3522367cd288f0b05170e2bd292c75b11fc3d2da2cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
